# analyze UNEAK data
library("ape")
library("pegas")
library("seqinr")
library("ggplot2")
library("adegenet")
library("vcfR")
library(tidyverse)
library(janitor)
library(sp)
library(rgdal)
library(raster)


# conStruct -----------------------------

library("conStruct")

# formatting data vignette
vignette(topic="format-data",package="conStruct")
# need structure format as input (or matrix with ind in rows and allele freq in columns for each locus)

#running analysis
vignette(topic="run-conStruct",package="conStruct")

# structure to conStruc 

agama <- structure2conStruct("data/agama.strct", onerowperind = TRUE,
                             start.loci = 3, start.samples = 3, missing.datum = 0,
                             outfile = "data/agama_conStruct") #samples start at 3 because of 2 headers

load("data/agama_conStruct.RData")
agama <- freqs #matrix loaded in with name 'freqs'

# edit rownames (make smaller)
rownames(agama) <- substr(rownames(agama), 1, 5)

load("data/basilisk_conStruct.RData")
basilisk <- freqs
rownames(basilisk) <- substr(rownames(basilisk), 1, 5)

# load coords file

agama_pts <- read.csv("data/agama_sites.csv") %>% dplyr::select(LONG, LAT) %>% 
  as.matrix()

bas_pts <- read.csv("data/basilisk_sites.csv") %>% dplyr::select(LONG, LAT) %>% 
  as.matrix()

## need to switch lat and long column order

#distance matrix

agama_dist <- dist(agama_pts) %>% as.matrix(.)

# run validation run to choose best k value

choose.k <- x.validation(n.reps = 2, K = 1:5, freqs = agama, geoDist = agama_dist,
                         coords = agama_pts, prefix = "Ktest", n.iter = 20000)
# need to do more reps, I think that was the problem, this time save files too

choose.k.again <- x.validation(n.reps = 10, K = 1:5, freqs = agama, geoDist = agama_dist,
                               coords = agama_pts, prefix = "choose.k.10fold", save.files = TRUE, 
                               make.figs = TRUE, n.iter = 5000
                              )

# * Assess results -----------------------------------

## ** BASILISK -----------------------------------------
#read in results in memory
sp.results <- Reduce("cbind", lapply(choose.k.again, function(x){unlist(x$sp)}), init = NULL)
nsp.results <- Reduce("cbind", lapply(choose.k.again, function(x){unlist(x$nsp)}), init = NULL)


# OR read in from file
sp.results <- as.matrix(
  read.table("data/basilisk/construct_run2/bv_choose.k.10fold_sp_xval_results.txt",
             header = TRUE,
             stringsAsFactors = FALSE)
)
nsp.results <- as.matrix(
  read.table("data/basilisk/construct_run2/bv_choose.k.10fold_nsp_xval_results.txt",
             header = TRUE,
             stringsAsFactors = FALSE)
)

# first, get the 95% confidence intervals for the spatial and nonspatial
#   models over values of K (mean +/- 1.96 the standard error)

sp.CIs <- apply(sp.results,1,function(x){mean(x) + c(-1.96,1.96) * sd(x)/length(x)})
nsp.CIs <- apply(nsp.results,1,function(x){mean(x) + c(-1.96,1.96) * sd(x)/length(x)})

# then, plot cross-validation results for K=1:5 with 8 replicates

plot(rowMeans(sp.results),
     pch=19,col="blue",
     ylab="predictive accuracy",xlab="values of K",
     ylim=range(sp.results,nsp.results),
     main="cross-validation results")
points(rowMeans(nsp.results),col="red",pch=19)
segments(x0 = 1:nrow(sp.results),
         y0 = sp.CIs[1,],
         x1 = 1:nrow(sp.results),
         y1 = sp.CIs[2,],
         col = "blue",lwd=2)
segments(x0 = 1:nrow(nsp.results),
         y0 = nsp.CIs[1,],
         x1 = 1:nrow(nsp.results),
         y1 = nsp.CIs[2,],
         col = "red",lwd=2)

# t-test for sig difference in clusters
t.test(sp.results[5,],nsp.results[5,],paired=TRUE,alternative="greater")
## spatial model sig. better than non spatial

## layer contributions
# Loop through output files generated by conStruct 
#   runs with K=1 through 5 and calculate the 
#   layer contributions for each layer in each run  

#spatial model 
layer.contributions <- matrix(NA,nrow=5,ncol=5)

#do k1 first
load("data/basilisk/construct_run2/bv_choose.k.10fold_sp_rep1K1_conStruct.results.Robj")
load("data/basilisk/construct_run2/bv_choose.k.10fold_sp_rep1K1_data.block.Robj")

# calculate layer contributions
layer.contributions[,1] <- c(calculate.layer.contribution(conStruct.results[[1]],data.block), rep(0,4))
tmp <- conStruct.results[[1]]$MAP$admix.proportions

#now add the rest
for(i in 2:5){
  # load the conStruct.results.Robj and data.block.Robj
  #   files saved at the end of a conStruct run
  load(sprintf("data/basilisk/construct_run2/bv_choose.k.10fold_sp_rep1K%s_conStruct.results.Robj",i))
  load(sprintf("data/basilisk/construct_run2/bv_choose.k.10fold_sp_rep1K%s_data.block.Robj",i))
  
  # match layers up across runs to keep plotting colors consistent
  #   for the same layers in different runs
  tmp.order <- match.layers.x.runs(tmp,conStruct.results[[1]]$MAP$admix.proportions)  
  
  # calculate layer contributions
  layer.contributions[,i] <- c(calculate.layer.contribution(conStruct.results=conStruct.results[[1]],
                                                            data.block=data.block,
                                                            layer.order=tmp.order),
                               rep(0,5-i))
  tmp <- conStruct.results[[1]]$MAP$admix.proportions[,tmp.order]
}

#plot layer contributions
barplot(layer.contributions,
        col=c("blue", "red", "goldenrod1", "forestgreen", "darkorchid1"),
        xlab="",
        ylab="layer contributions",
        names.arg=paste0("K=",1:5))


#spatial model 
layer.contributions.nsp <- matrix(NA,nrow=5,ncol=5)

#do k1 first
load("data/basilisk/choose.k.10fold_sp_rep2K1_conStruct.results.Robj")
load("data/basilisk/choose.k.10fold_sp_rep2K1_data.block.Robj")

# calculate layer contributions
layer.contributions.nsp[,1] <- c(calculate.layer.contribution(conStruct.results[[1]],data.block),rep(0,4))
tmp.nsp <- conStruct.results[[1]]$MAP$admix.proportions

#now add the rest
for(i in 2:5){
  # load the conStruct.results.Robj and data.block.Robj
  #   files saved at the end of a conStruct run
  load(sprintf("data/basilisk/choose.k.10fold_sp_rep2K%s_conStruct.results.Robj",i))
  load(sprintf("data/basilisk/choose.k.10fold_sp_rep2K%s_data.block.Robj",i))
  
  # match layers up across runs to keep plotting colors consistent
  #   for the same layers in different runs
  tmp.order <- match.layers.x.runs(tmp.nsp,conStruct.results[[1]]$MAP$admix.proportions)  
  
  # calculate layer contributions
  layer.contributions.nsp[,i] <- c(calculate.layer.contribution(conStruct.results=conStruct.results[[1]],
                                                            data.block=data.block,
                                                            layer.order=tmp.order),
                               rep(0,5-i))
  tmp.nsp <- conStruct.results[[1]]$MAP$admix.proportions[,tmp.order]
}

#plot layer contributions
barplot(layer.contributions.nsp,
        col=c("blue", "red", "goldenrod1", "forestgreen", "darkorchid1"),
        xlab="",
        ylab="layer contributions",
        names.arg=paste0("K=",1:5))


## since the 5th layer has strong contribution, lets use k5 nonspatial

## plotting results

# load results

load("data/agama/choose.k.10fold_nsp_rep1K3_conStruct.results.Robj")
load("data/agama/choose.k.10fold_nsp_rep1K3_data.block.Robj")

# pull admixture proportions

admix_props <- conStruct.results$chain_1$MAP$admix.proportions

# make structure plot

make.structure.plot(admix.proportions = admix_props, sample.names = rownames(basilisk))

make.structure.plot(admix.proportions = admix_props,
                    sample.order = order(agama_pts[,2]), sample.names = rownames(agama)) #order by lat or long

# pie chart


# make the desired map
maps::map(database = "county", xlim = range(agama_pts[,1]) + c(-0.01, 0.01), 
          ylim = range(agama_pts[,2]) + c(-0.01,0.01), col="gray")

# add the admixture pie plot
make.admix.pie.plot(admix.proportions = admix_props,
                    coords = agama_pts,
                    add = TRUE)


# add pie plot to an existing map

# make the desired map
maps::map(xlim = range(data.block$coords[,1]) + c(-0.01,0.01), ylim = range(data.block$coords[,2])+c(-0.01,0.01), col="gray")

# add the admixture pie plot
make.admix.pie.plot(admix.proportions = admix_props,
                    coords = data.block$coords, radii = 2,
                    add = TRUE)


# radiator ---------------

devtools::install_github("thierrygosselin/radiator")
library(radiator)
library(stringr)
BiocManager::install("SeqArray")
#check for version 1.28.1 of SeqArray
devtools::package_info(pkgs = "SeqArray") #can't seem to get updated version...

#test that package identifies correct format
radiator::detect_genomic_format(data = "D:/lizard_genomics/UNEAK/HapMap/VCF.vcf")
# yes

# create strata file
strata <- radiator::extract_individuals_vcf("D:/lizard_genomics/UNEAK/HapMap/VCF.vcf") %>%
  dplyr::mutate(STRATA = dplyr::case_when(str_detect(INDIVIDUALS, "AG") ~ "agama",
                                          str_detect(INDIVIDUALS, "BV") ~ "basilisk",
                                          str_detect(INDIVIDUALS, "Blank") ~ "blank")) %>%
  readr::write_tsv(x = ., file = "data/strata.tsv")

#read vcf

vcf <- radiator::read_vcf("D:/lizard_genomics/UNEAK/HapMap/VCF.vcf", 
                          strata = "data/strata.tsv",
                          parallel.core = 1L,
                          filter.common.markers = FALSE)


data <- radiator::filter_rad(
  data = "D:/lizard_genomics/UNEAK/HapMap/VCF.vcf",
  strata = "data/strata.tsv", 
  output = c("structure", "genind"),
  parallel.core = 1L
)


#generate strata

# create tidy vcf

tidy <- radiator::tidy_vcf(data = "D:/lizard_genomics/UNEAK/HapMap/VCF.vcf",
                           strata = "data/strata.tsv")

#split vcf


#now convert vcf to structure file

lizard <- genomic_converter(data = "D:/lizard_genomics/UNEAK/HapMap/VCF.vcf", parallel.core = 1L,
                            output = "structure")

##CANT GET TO WORK


## converting files -----------------------------------

## function to convert HapMap (Tassel) to adegenet genind format
hapMap2genind <- function(file){
  require(adegenet)
  hapmap <- read.table(file, header=TRUE, row.names=1, sep="\t",
                       stringsAsFactors=FALSE)
  samples <- names(hapmap)[11:length(hapmap)]
  conv <- c("AA", "CC", "TT", "GG", "AC", "AT", "AG", "CT", "CG", "TG", NA)
  names(conv) <- c("A", "C", "T", "G", "M" , "W", "R", "Y", "S",  "K", "N")
  mydf <- matrix(NA, nrow=dim(hapmap)[1], ncol=length(samples),
                 dimnames=list(row.names(hapmap), samples))
  for(i in 1:length(samples)){
    mydf[,i] <- conv[hapmap[[i+10]]]
  }
  mydf <- as.data.frame(t(mydf))
  x <- df2genind(mydf, type="codom", sep = "\t")
  return(x)
}

mydata <- hapMap2genind("D:/lizard_genomics/UNEAK/HapMap/HapMap.hmp.txt")

# OR read in VCF file exported from tassel (saved hapmap file as VCF)

vcf <- read.vcfR("D:/lizard_genomics/UNEAK/HapMap/VCF.vcf")
#split agama and basilisk
agama_vcf <- vcf[samples = 1:45]
basilisk_vcf <- vcf[samples = 46:95]

#convert to genind object
agama_genind <- vcfR2genind(agama_vcf)

agama_matrix <- as.matrix(agama_genind)
rownames(agama_matrix) <- substr(rownames(agama_matrix), 1, 5)

basilisk_genind <- vcfR2genind(basilisk_vcf)

# get raw genotype matrix

#agama_gen <- t(agama_vcf@gt) %>% .[-1,] %>% janitor::remove_empty("cols")

#create genlight object
agama_genlight <- new("genlight", agama_matrix, parallel=FALSE)


##pca analysis
pca_ag <- glPca(agama_genlight)


# adegenet -------------------------------

# read in VCF file exported from tassel (saved hapmap file as VCF)

#read in updated ones
agama_vcf <- read.vcfR("D:/lizard_genomics/UNEAK/hapMap/agama_update.vcf")


basilisk_vcf <- read.vcfR("D:/lizard_genomics/UNEAK/hapMap/basilisk_update.vcf")

#add new vcf with different SNP #s (for some reason running the same filter
# again in Tassel5 gave ~500 more SNPS)

agama_vcf2 <- read.vcfR("D:/lizard_genomics/UNEAK/hapMap/agama_filtered2.vcf")

#convert to genind object
agama_genind <- vcfR2genind(agama_vcf)

agama_df <- as.data.frame(agama_genind) %>% mutate(sample = substr(rownames(.), 1, 5)) %>% 
  dplyr::select(sample, everything())

agama_genind2 <- vcfR2genind(agama_vcf2)

agama_df2 <- as.data.frame(agama_genind2) %>% mutate(sample = substr(rownames(.), 1, 5)) %>% 
  dplyr::select(sample, everything())

diff <- agama_df2 %>% dplyr::select(!colnames(agama_df))

basilisk_genind <- vcfR2genind(basilisk_vcf)
rownames(basilisk_genind@tab) <-  substr(rownames(basilisk_genind@tab), 1, 5)


basilisk_df <- as.data.frame(basilisk_genind) %>% mutate(sample = substr(rownames(.), 1, 5)) %>% 
  dplyr::select(sample, everything())

# calculate pairwise distances

agama_fst <- hierfstat::pairwise.neifst(agama_df, diploid = TRUE)


basilisk_fst <-  hierfstat::pairwise.neifst(basilisk_df, diploid = TRUE)

#calculate chords distance, Bill says better than fst

agama_chord <- hierfstat::genet.dist(agama_df, diploid = TRUE, method = "Dch")

# read in old chord file to see if tightly correlated (hopefully)

agama_old <- read.csv("data/agama_chord.csv") %>% dplyr::select(-1)

#almost perfectly correlated: 0.9996081

write.csv(as.matrix(agama_chord), "data/agama_chord_update.csv") #note that first column is pop #


basilisk_chord <- hierfstat::genet.dist(basilisk_df, diploid = TRUE, method = "Dch")
write.csv(as.matrix(basilisk_chord), "data/basilisk_chord_update.csv")

# calculate individual based pairwise distances

devtools::install_github("nspope/radish")
library(radish) #won't work for R version

#calculate Dps

agama_dps <- propShared(agama_genind)
agama_dps <- 1 - agama_dps
write.csv(agama_dps, "data/agama_dps.csv")

basilisk_dps <- propShared(basilisk_genind)
basilisk_dps <- 1 - basilisk_dps
write.csv(basilisk_dps, "data/basilisk_dps.csv")

